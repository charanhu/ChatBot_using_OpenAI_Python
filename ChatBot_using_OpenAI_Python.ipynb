{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatBot using OpenAI and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install gradio\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatBot using OpenAI and Python\n",
    "\n",
    "# Importing the libraries\n",
    "import openai\n",
    "import gradio as gr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the API key\n",
    "openai.api_key = \"YOUR API KEY\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI ChatBot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function\n",
    "def ChatBot(question):  # prompt is the input\n",
    "    response = openai.Completion.create(  # response is the output\n",
    "        engine=\"text-davinci-003\",  # using the davinci model\n",
    "        prompt=question,  # prompt is the input\n",
    "        temperature=0.5,  # temperature is the randomness of the output\n",
    "        max_tokens=1024,  # max_tokens is the number of tokens in the output\n",
    "        n=1,  # n is the number of outputs\n",
    "    )\n",
    "    message = response.choices[0].text  # message is the output\n",
    "    return message.strip()  # strip() is used to remove the extra spaces\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Interface Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the interface of the ChatBot\n",
    "# question is the input and chatHistory is also the input\n",
    "def ChatBot_Interface(question, chatHistory):\n",
    "    # call the function and pass the question as the input\n",
    "    answer = ChatBot(question)\n",
    "    # append the question and answer to the chatHistory\n",
    "    chatHistory.append(question, answer)\n",
    "    # here two chatHistory is returned because to show the chatHistory in the interface AND to pass the chatHistory to the next question\n",
    "    return chatHistory, chatHistory\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the interface\n",
    "gr.Interface(fn=ChatBot_Interface,\n",
    "             # question is the input and chatHistory is also the input\n",
    "             inputs=[\"text\", 'state'],\n",
    "             outputs=[\"chatbot\", 'state']).launch()  # chatHistory and answer is the output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
